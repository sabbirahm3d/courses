{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 14 - Starter Code\n",
    "\n",
    "Natural Language Processing and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "nlp_toolkit = English()\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will compare some of the classical NLP tools from the last class with these more modern latent variable techniques.  We will do this by comparing information extraction on Twitter using two different methods.\n",
    "\n",
    "> NOTE:  There is a pre-existing file of captured tweets you can use.  It is located in the class repo for lesson-14.  However, you can also collect your own tweets following the instructions in twitter-instructions.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the twitter data\n",
    "tweets = [unicode(tweet, errors='ignore') for tweet in \\\n",
    "          open('../../assets/dataset/captured-tweets.txt', 'r')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using `spacy`\n",
    "\n",
    "Use `spacy` to write a function to filter tweets down to those where Google is announcing a product. How might we do this? One way might be to identify verbs, where 'Google' is the noun and there is some action like 'announcing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use spacy to parse each tweet\n",
    "parsed_tweets = []\n",
    "for tweet in tweets:\n",
    "    parsed_tweets.append(nlp_toolkit(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a\n",
    "Write a function that can take a sentence parsed by spacy and identify if it mentions a company named 'Google'. Remember,spacy can find entities and code them as ORG if they are a company. \n",
    "\n",
    "### 1.b\n",
    "BONUS: Make this function work for any company.\n",
    "\n",
    "Hint: https://spacy.io/docs#examples-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a take a sentence parsed by `spacy` and \n",
    "# identify if it mentions a company named 'Google'. \n",
    "# Remember, `spacy` can find entities and code them `ORG` if they are a company.\n",
    "def mentions_company(parsed, company='Google'):\n",
    "    for entity in parsed.ents:\n",
    "        if ### FILL IN ###\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each tweet, use parsed tweet to check your function\n",
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    if mentions_company(parsed_tweet, 'Google'):\n",
    "        print parsed_tweet\n",
    "        if i>10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c\n",
    "Write a function that can take a sentence parsed by spacy and return the verbs of the sentence (preferably lemmatized).\n",
    "\n",
    "Hint: https://spacy.io/docs#examples-pos-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a sentence parsed by `spacy` \n",
    "# and return the verbs of the sentence (preferably lemmatized)\n",
    "def get_actions(parsed):\n",
    "    actions = [el.lemma_ \n",
    "                for el in parsed \n",
    "                if ### FILL IN ###\n",
    "               ]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each tweet, use parsed tweet to check your function\n",
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    print get_actions(parsed_tweet)\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d\n",
    "\n",
    "For each tweet that mentions Google, parse it using spacy and print it out if the tweet has 'release' or 'announce' as a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    ### FILL IN ###\n",
    "    print(parsed_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.e\n",
    "Write a function that identifies countries.  HINT: the entity label for countries is GPE (or \"GeoPolitical Entity\").\n",
    "\n",
    "Hint: https://spacy.io/docs#annotation-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write a function that identifies countries - HINT: the entity label for \n",
    "# countries is GPE (or GeoPolitical Entity)\n",
    "def mentions_country(parsed, country):\n",
    "    for entity in parsed.ents:\n",
    "        if ### FILL IN ###\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    if mentions_country(parsed_tweet, 'Iran'):\n",
    "        print parsed_tweet\n",
    "        if i>1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.f\n",
    "Re-run to find country tweets that discuss 'Iran' announcing or releasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    ### FILL IN ###\n",
    "    print(parsed_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using `gensim`\n",
    "\n",
    "Build a `word2vec` model of the tweets we have collected using `gensim`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a\n",
    "First take the collection of tweets and tokenize them using spacy.\n",
    "Think about how this should be done. \n",
    "Should you only use upper-case or lower-case? \n",
    "Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lemmatize the verbs for easier searching and keep symbols and punctuations\n",
    "split_tweets = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                 for x in nlp_toolkit(t)] for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print split_tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b\n",
    "Build a word2vec model.  \n",
    "Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a `word2vec` model\n",
    "model = Word2Vec(split_tweets, size=100, window=4, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c\n",
    "Test your word2vec model with a few similarity functions.  \n",
    "Find words similar to 'Syria'.  \n",
    "Find words similar to 'war'.  \n",
    "Find words similar to 'Iran'.  \n",
    "Find words similar to 'Verizon'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Verizon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['war', 'Iraq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Comparing `spacy` and `gensim`\n",
    "Filter tweets to those that mention 'Iran' or similar entities and 'war' or similar entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a\n",
    "Using `spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using spacy\n",
    "for i, parsed_tweet in enumerate(parsed_tweets):\n",
    "    if mentions_country(parsed_tweet, 'Iran') \\\n",
    "    or mentions_country(parsed_tweet, 'Iraq'):\n",
    "        if 'attack' in get_actions(parsed_tweet) \\\n",
    "        or 'war' in parsed_tweet.text:\n",
    "            print(parsed_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "### 3.b\n",
    "Using `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using gensim\n",
    "for i, split_tweet in enumerate(split_tweets):\n",
    "    similarity_to_iran = max([model.similarity('Iran', tok) for tok in split_tweet if tok in model.vocab]+[0])\n",
    "    similarity_to_war = max([model.similarity('war', tok) for tok in split_tweet if tok in model.vocab]+[0])\n",
    "    if similarity_to_iran > 0.999 and similarity_to_war > 0.999:\n",
    "        print (similarity_to_iran, similarity_to_war)\n",
    "        print ' '.join(split_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 4: [Bonus] Your Own Analysis\n",
    "Build your own analysis using the above twitter data.\n",
    "Alternatively, collect your own tweets to analyze following the instructions in `twitter-instructions.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
