{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Class 10 - Starter Code\n",
    "\n",
    "Predicting Evergreeness of Content using Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load Dataset and Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"../../assets/dataset/stumbleupon.tsv\", sep='\\t')\n",
    "\n",
    "# Split `boilerplate` column\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "\n",
    "# Check head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting \"Greenness\" Of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise uses the [Kaggle StumbleUpon Evergreen Classification Challenge](https://www.kaggle.com/c/stumbleupon)\n",
    "\n",
    "This dataset comes from [StumbleUpon](https://www.stumbleupon.com/), a web page recommender. A description of the columns is below:\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are 'evergreen' sites?\n",
    "\n",
    "> #### Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. \n",
    "\n",
    "> #### A sample of URLs is below, where label = 1 are 'evergreen' websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check URLs and their evergreen labels\n",
    "data[['url', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Does being a news site affect evergreeness? \n",
    "Compute or plot the percentage of news related evergreen sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using groupby()\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using a plot\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Does category in general affect evergreeness? \n",
    "Plot the rate of evergreen sites for all Alchemy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using groupby()\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using a plot\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 How many articles are there per category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using groupby()\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using a plot\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Explore additional relationships\n",
    "Are there any other relationships you brainstormed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Can you create any additional features?\n",
    "Create a feature that indicates whether the title contains the word 'recipe'. Is the percent of evegreen websites higher or lower on pages that have recipe in the the title?\n",
    "\n",
    "Hint: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if title contains the word 'recipe'\n",
    "data['recipe_in_title'] = data['title'].str.contains('recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using groupby()\n",
    "data.groupby(['recipe_in_title'])[['label']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using a plot\n",
    "sns.factorplot(x='recipe_in_title', y='label', kind='bar', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2:  Let's Explore Some Decision Trees\n",
    "\n",
    "Demo: Build a decision tree model to predict the \"evergreeness\" of a given website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check dtypes and missing values\n",
    "pd.DataFrame({'dtypes': data.dtypes, 'missing':data.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Create dummy variables for alchemy_category\n",
    "data = (data.join(pd.get_dummies(data['alchemy_category'], prefix='alchemy_cat'))\n",
    "            .drop(['alchemy_category'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Set features to use\n",
    "features = ['image_ratio', 'html_ratio', 'recipe_in_title'] + \\\n",
    "            filter(lambda x: x.startswith('alchemy_cat_'), data.columns)\n",
    "\n",
    "# Set target variable name\n",
    "target = 'label'\n",
    "\n",
    "# Set X and y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Create separate training and test sets with 60/40 train/test split\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Instantiate model using default params\n",
    "tm = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Train model on training set\n",
    "tm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy of model on test set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_test, y_test)\n",
    "\n",
    "# Evaluate ROC AUC score of model on test set\n",
    "print 'ROC AUC: %0.3f' % metrics.roc_auc_score(y_test, tm.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 Evaluate the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get confusion matrix on test set\n",
    "y_pred = tm.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.heatmap(cm_normalized, annot=True)\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xlabel('Pred')\n",
    "plt.show()\n",
    "\n",
    "print \"Confusion Matrix:\"\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 3: Adjusting Decision Trees to Avoid Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check if the model is overfit by checking accuracy on training set vs test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model on train set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_train, y_train)\n",
    "\n",
    "# Evaluate model on test set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Demo: Control for overfitting in the decision model by adjusting the maximum number of questions (max_depth) or the minimum number of records in each final node (min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model using default params\n",
    "tm = tree.DecisionTreeClassifier(max_depth=2, min_samples_leaf=5)\n",
    "\n",
    "# Train model on training set\n",
    "tm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model on train set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_train, y_train)\n",
    "\n",
    "# Evaluate model on test set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Random Forests\n",
    "\n",
    "### 4.1 Demo: Build a random forest model to predict the evergreeness of a website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# Instantiate model\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "# Train model on training set\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate model on train set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_train, y_train)\n",
    "\n",
    "# Evaluate model on test set\n",
    "print \"Accuracy: %0.3f\" % tm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tune and update the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set list of values to grid search over\n",
    "n = [1, 2, 3, 10, 20, 30, 100, 200, 300]\n",
    "params = {'n_estimators': n}\n",
    "\n",
    "# Perform grid search using list of values\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(),\n",
    "    param_grid=params)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Get best value to use\n",
    "print \"Best Params:\"\n",
    "print gs.best_params_\n",
    "\n",
    "# Get improvement\n",
    "print \"Accuracy of current model: %0.3f\" % rf.score(X_test, y_test)\n",
    "print \"Accuracy using best param: %0.3f\" % gs.best_score_\n",
    "\n",
    "# Plot scores\n",
    "plt.plot(n, [s[1] for s in gs.grid_scores_])\n",
    "\n",
    "\n",
    "\n",
    "# Current model params\n",
    "print rf\n",
    "print \"Accuracy of current model: %0.3f\" % rf.score(X_test, y_test)\n",
    "\n",
    "# Update model params\n",
    "rf.set_params(n_estimators=gs.best_params_['n_estimators'])\n",
    "\n",
    "# Retrain model on new params\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Updated model params\n",
    "print rf\n",
    "print \"Accuracy of updated model: %0.3f\" % rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Extract Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot importances for all features\n",
    "features = X.columns\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'Features': features, 'Importance Score': feature_importances})\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to combine dummy features importances\n",
    "def combine_dummies(dummy_prefixes):\n",
    "    for p in dummy_prefixes:\n",
    "        sub_keys = filter(lambda x: x.startswith(p), feature_dict)\n",
    "        sub_keys_sum = sum([feature_dict[x] for x in sub_keys])\n",
    "        for k in sub_keys: feature_dict.pop(k)\n",
    "        feature_dict[p] = sub_keys_sum\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot importances with dummy features combined\n",
    "feature_names = X.columns\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_dummy_prefixes = ['alchemy_cat_']\n",
    "\n",
    "feature_dict = dict(zip(feature_names, feature_importances))\n",
    "feature_dict = combine_dummies(feature_dummy_prefixes)\n",
    "\n",
    "features_df = pd.DataFrame(feature_dict.items(), columns=['Features', 'Importance Score'])\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Improve Random Forest Model through Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Independent Practice: Improve model using additional (new and existing) features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Continue adding input variables to the model that you think may be relevant\n",
    "2. For each feature:\n",
    "  - Evaluate the model for improved predictive performance using cross-validation\n",
    "  - Evaluate the _importance_ of the feature\n",
    "  - \n",
    "3. **Bonus**: Just like the 'recipe' feature, add in similar text features and evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new feature to check if title contains the word 'recipe'\n",
    "data['year_in_title'] = data['title'].str.contains('2010') | \\\n",
    "                        data['title'].str.contains('2011') | \\\n",
    "                        data['title'].str.contains('2012') | \\\n",
    "                        data['title'].str.contains('2013')\n",
    "            \n",
    "# Create additional new features\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set features to use\n",
    "features = ### FILL IN ###\n",
    "\n",
    "# Set target variable name\n",
    "target = ### FILL IN ###\n",
    "\n",
    "# Set X and y\n",
    "X = ### FILL IN ###\n",
    "y = ### FILL IN ###\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "rf = ### FILL IN ###\n",
    "\n",
    "# Train model on training set\n",
    "rf.### FILL IN ###\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate accuracy of model on test set\n",
    "print \"Accuracy: %0.3f\" % rf.score(X_test, y_test)\n",
    "\n",
    "# Evaluate ROC AUC score of model on test set\n",
    "print 'ROC AUC: %0.3f' % metrics.roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# Plot importances with dummy features combined\n",
    "feature_names = X.### FILL IN ###\n",
    "feature_importances = rf.### FILL IN ###\n",
    "feature_dummy_prefixes = ['alchemy_cat_']\n",
    "\n",
    "feature_dict = dict(zip(feature_names, feature_importances))\n",
    "feature_dict = combine_dummies(feature_dummy_prefixes)\n",
    "\n",
    "features_df = pd.DataFrame(feature_dict.items(), columns=['Features', 'Importance Score'])\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
