{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 13 - Starter Code\n",
    "\n",
    "Natural Language Processing and Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Pre-Process\n",
    "\n",
    "We will continue to use the [Kaggle StumbleUpon Evergreen Classification Challenge](https://www.kaggle.com/c/stumbleupon) for this exercise.\n",
    "\n",
    "This dataset comes from [StumbleUpon](https://www.stumbleupon.com/), a web page recommender. A description of the columns is below:\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only\n",
    "\n",
    "### What are 'evergreen' sites?\n",
    "\n",
    "> #### Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"../../assets/dataset/stumbleupon.tsv\", sep='\\t')\n",
    "\n",
    "# Split `boilerplate` column\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))\n",
    "\n",
    "# Check info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: [Demo] Using `spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up spaCy\n",
    "from spacy.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a title to parse\n",
    "title = data['title'].values[0]\n",
    "print title\n",
    "print type(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse title using spacy\n",
    "parsed = nlp(title)\n",
    "\n",
    "# Print parsed results\n",
    "for (i, word) in enumerate(parsed):\n",
    "    print(\"Word: {}\".format(word))\n",
    "    print(\"\\t Phrase type: {}\".format(word.dep_))\n",
    "    print(\"\\t Is the word a known entity type? {}\".format(word.ent_type_  if word.ent_type_ else \"No\"))\n",
    "    print(\"\\t Lemma: {}\".format(word.lemma_))\n",
    "    print(\"\\t Parent of this word: {}\".format(word.head.lemma_))\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: [Review] Using Manual Text Features\n",
    "\n",
    "### 2.1 How did we previously generate text features?\n",
    "We manually created the `recipe_in_title` text feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if title contains the word 'recipe'\n",
    "data['recipe_in_title'] = data['title'].str.contains('recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set features to use\n",
    "existing_features = ['image_ratio', 'html_ratio']\n",
    "new_text_features = ['recipe_in_title']\n",
    "features = existing_features + new_text_features\n",
    "\n",
    "# Set target variable name\n",
    "target = 'label'\n",
    "\n",
    "# Set X and y\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "# Create separate training and test sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Train model on training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate accuracy of model on test set\n",
    "print \"Accuracy: %0.3f\" % clf.score(X_test, y_test)\n",
    "\n",
    "# Evaluate ROC AUC score of model on test set\n",
    "print 'ROC AUC: %0.3f' % metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "# Plot feature importances\n",
    "feature_names = X.columns\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "features_df = pd.DataFrame(feature_dict.items(), columns=['Features', 'Importance Score'])\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: [Demo] Using `CountVectorizer`\n",
    "\n",
    "### 3.1 Count Vectorizer Demo\n",
    "Use `CountVectorizer` to generate vectorized text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This is the second second document.',\n",
    "          'And the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "# Use `fit` to learn the vocabulary of the corpus\n",
    "V = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dimensions of the vectorized matrix are\n",
    "print \"Dimensions of V:\"\n",
    "print V.shape\n",
    "\n",
    "# Num. of rows = num of records in corpus\n",
    "print \"Records (documents/sentences) in Corpus:\"\n",
    "print len(corpus)\n",
    "\n",
    "# Num. of columns = num of features\n",
    "print \"Size (words) in Vocabulary:\"\n",
    "print len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get words in vocabulary\n",
    "print vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.transform(['This document is a completely new document.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Generate Text Features for `data['title']` using Count Vectorizer\n",
    "Use `CountVectorizer` to generate vectorized text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 1000,\n",
    "                             ngram_range=(1, 2),\n",
    "                             stop_words='english',\n",
    "                             binary=True)\n",
    "\n",
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectorizer.fit(data['title'])\n",
    "\n",
    "# Use `tranform` to generate the vectorized matrix\n",
    "X_new_text_features = vectorizer.transform(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set features to use\n",
    "existing_features = ['image_ratio', 'html_ratio']\n",
    "\n",
    "# Set target variable name\n",
    "target = 'label'\n",
    "\n",
    "# Get X\n",
    "X_existing_features = data[existing_features]\n",
    "\n",
    "# Set X and y\n",
    "X = sp.sparse.hstack((X_new_text_features, X_existing_features)).toarray()\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "# Create separate training and test sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Train model on training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate accuracy of model on test set\n",
    "print \"Accuracy: %0.3f\" % clf.score(X_test, y_test)\n",
    "\n",
    "# Evaluate ROC AUC score of model on test set\n",
    "print 'ROC AUC: %0.3f' % metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "# Plot feature importances\n",
    "feature_names = vectorizer.get_feature_names() + existing_features\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "features_df = pd.DataFrame(feature_dict.items(), columns=['Features', 'Importance Score'])\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Generate Text Features for `data['body']` using Count Vectorizer\n",
    "Use `CountVectorizer` to generate vectorized text feature for `data['body']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create vectorized text feature matrix for data['body']\n",
    "\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set features to use\n",
    "existing_features = ['image_ratio', 'html_ratio']\n",
    "\n",
    "# Set target variable name\n",
    "target = 'label'\n",
    "\n",
    "# Get X\n",
    "X_existing_features = data[existing_features]\n",
    "\n",
    "# Set X and y\n",
    "X = sp.sparse.hstack((X_new_text_features, X_existing_features)).toarray()\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "# Create separate training and test sets\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Train model on training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate accuracy of model on test set\n",
    "print \"Accuracy: %0.3f\" % clf.score(X_test, y_test)\n",
    "\n",
    "# Evaluate ROC AUC score of model on test set\n",
    "print 'ROC AUC: %0.3f' % metrics.roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "\n",
    "# Plot feature importances\n",
    "feature_names = vectorizer.get_feature_names() + existing_features\n",
    "feature_importances = clf.feature_importances_\n",
    "feature_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "features_df = pd.DataFrame(feature_dict.items(), columns=['Features', 'Importance Score'])\n",
    "features_df.sort_values('Importance Score', inplace=True, ascending=False)\n",
    "sns.barplot(y='Features', x='Importance Score', data=features_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: [Exercise] Using `TfidfVectorizer`\n",
    "\n",
    "### 4.1 Generate Text Features for `data['body']` using TF-IDF Vectorizer\n",
    "Use `TfidfVectorizer` to generate vectorized text features.\n",
    "Does it perform better than `CountVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create vectorized text feature matrix for data['body']\n",
    "\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build RF model using 'image_ratio', 'html_ratio', and TF-IDF vectorized features for 'body'\n",
    "\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
