{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In project 2, we conducted an exploratory analysis on the Admissions dataset. In this project, we will now build a model to predict whether someone is admitted to grad school based on their GRE score, undergrad GPA, and the prestige of their undergrad school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import neighbors\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Load Dataset\n",
    "\n",
    "#### 1.1 Let's load the dataset and check the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../assets/admissions.csv\")\n",
    "\n",
    "# check head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Pre-Process Data\n",
    "\n",
    "#### 2.1 Check and remove missing values\n",
    "**Reading**: Read Pandas docs on handling missing values:\n",
    "[http://pandas.pydata.org/pandas-docs/stable/missing_data.html](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for missing values in each column before dropping\n",
    "print \"Missing values:\"\n",
    "print df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop missing values if there are any\n",
    "if df.isnull().sum().sum():\n",
    "    print \"There are missing values\"\n",
    "    df = df.dropna()\n",
    "    print \"Missing values dropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for missing values in each column after dropping\n",
    "print \"Missing values:\"\n",
    "print df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Check and convert all data types to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check data types\n",
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get numerical columns\n",
    "num_cols = set(df.dtypes[((df.dtypes==\"int64\")|(df.dtypes==\"float64\"))].index)\n",
    "non_cols = set(df.columns)-num_cols\n",
    "\n",
    "print \"Numerical columns:\"\n",
    "print num_cols\n",
    "print \"Non-numerical columns:\"\n",
    "print non_cols\n",
    "\n",
    "# here all columns are numeric; no need to convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Check and create dummy variables for categorical features\n",
    "**Reading**: API Docs for `get_dummies()`:\n",
    "[http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummy variables for `prestige` feature\n",
    "# this check allows this code to be run multiple times\n",
    "if 'prestige' in df.columns:\n",
    "    # get dummy variables for prestige\n",
    "    df = df.join(pd.get_dummies(df['prestige'], prefix='prestige'))\n",
    "    # remove prestige column\n",
    "    df.drop(['prestige'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for newly added columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Cross Validation\n",
    "\n",
    "#### 3.1 Create separate training and test sets\n",
    "**Reading**:\n",
    "\n",
    "Read Scikit docs on cross validation:\n",
    "[http://scikit-learn.org/stable/modules/cross_validation.html](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "Read Scikit docs on `sklearn.cross_validation.train_test_split()`:\n",
    "[http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set X and y\n",
    "X = df.drop(['admit'], axis=1)\n",
    "y = df['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create separate training and test set with 60/40 train/test split\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check size of training set\n",
    "print X_train.shape, y_train.shape\n",
    "\n",
    "# check size of test set\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Build Model\n",
    "\n",
    "#### 4.1 Build KNN Classifier\n",
    "**Reading**: Read Scikit docs for `sklearn.neighbors.KNeighborsClassifier`:\n",
    "[http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate knn classifier using default params\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# train knn classifier on training set\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Evaluate Model\n",
    "**Reading**: Read Scikit docs on evaluating models: [http://scikit-learn.org/stable/modules/model_evaluation.html](http://scikit-learn.org/stable/modules/model_evaluation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check model accuracy on test set\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print \"Accuracy: \" + str(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: Read Scikit docs on confusion matrix: [http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get confusion matrix on test set\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.heatmap(cm_normalized, annot=True)\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xlabel('Pred')\n",
    "plt.show()\n",
    "\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Tune Model\n",
    "\n",
    "#### 5.1 Perform Grid Search for `n_neighbors`\n",
    "**Reading**: Read Scikit docs for `sklearn.grid_search.GridSearchCV`:\n",
    "[http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set list of values to grid search over\n",
    "k = range(2, 25)\n",
    "params = {'n_neighbors': k}\n",
    "\n",
    "# perform grid search using list of values\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=neighbors.KNeighborsClassifier(),\n",
    "    param_grid=params)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# get best value to use\n",
    "print gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot search values vs. grid scores\n",
    "plt.plot(k, [s[1] for s in gs.grid_scores_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Update model using best `n_neighbors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate knn classifier using updated params\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# train updated knn classifier on training set\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Evaluate updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check updated model accuracy on test set\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print \"Accuracy: \" + str(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get confusion matrix on test set\n",
    "y_pred = knn.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = plt.axes()\n",
    "sns.heatmap(cm_normalized, annot=True)\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xlabel('Pred')\n",
    "plt.show()\n",
    "\n",
    "print cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** This is not a good model. Perhaps the data set is too small or the features themselves do not have enough predictive capability. However, the steps taken in this project are valid and applicable to future classifications problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
