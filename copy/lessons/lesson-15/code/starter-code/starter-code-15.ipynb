{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 15 - Starter Code\n",
    "\n",
    "Exploring Rossmann Drug Store Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Pre-Process\n",
    "\n",
    "We will use the [Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) dataset for this exercise.  \n",
    "\n",
    "Data Dictionary from Kaggle  \n",
    "\n",
    "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n",
    "\n",
    "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
    "\n",
    "* Id - an Id that represents a (Store, Date) duple within the test set\n",
    "* **Store** - a unique Id for each store\n",
    "* **Sales** - the turnover for any given day (this is what you are predicting)\n",
    "* **Customers** - the number of customers on a given day\n",
    "* **Open** - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "* **StateHoliday** - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "* **SchoolHoliday** - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "* Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "* CompetitionDistance - distance in meters to the nearest competitor store\n",
    "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "* **Promo** - indicates whether a store is running a promo on that day\n",
    "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "* Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n",
    "\n",
    "\n",
    "We will use a subset of these features for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../../assets/dataset/rossmann.csv', skipinitialspace=True, low_memory=False)\n",
    "\n",
    "# Check info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are most interested in the `Date` column that contains the date of sales for each store, we will make sure to process that as a `DateTime` type, and make that the index of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to datetime object\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Use `Date` as index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Add extra columns to break out month and year\n",
    "data['Year'] = data.index.year\n",
    "data['Month'] = data.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the date as index allows us to filter easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter for a particular year\n",
    "data['2014'].head()\n",
    "\n",
    "# Or month\n",
    "data['2014-05'].head()\n",
    "\n",
    "# Or date\n",
    "data['2014-06-22'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over a million sales data points in this dataset, so for some analysis we will focus on just one store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter for a single store\n",
    "store1_data = data[data['Store'] == 1]\n",
    "\n",
    "# Check sample\n",
    "store1_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exploration and Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare sales on holidays, we can compare the sales using box-plots, which allows us to compare the distribution of sales on holidays against all other days. On state holidays the store is closed (and as a nice sanity check there are 0 sales), and on school holidays the sales are relatively similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot sales vs school holiday\n",
    "sns.factorplot(\n",
    "    x='SchoolHoliday',\n",
    "    y='Sales',\n",
    "    data=store1_data, \n",
    "    kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**: See if there is a difference affecting sales on promotion days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot sales vs promotion days\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare sales across days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot sales vs day of week\n",
    "sns.factorplot(\n",
    "    col='Open',\n",
    "    x='DayOfWeek',\n",
    "    y='Sales',\n",
    "    data=store1_data,\n",
    "    kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to identify larger-scale trends in our data. How did sales change from 2014 to 2015? Were there any particularly interesting outliers in terms of sales or customer visits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter to days store 1 was open\n",
    "store1_open_data = store1_data[store1_data.Open==1]\n",
    "\n",
    "# Plot sales over time\n",
    "store1_open_data['Sales'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot customer visits over time\n",
    "store1_open_data['Customers'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**: Use the index filtering to filter to just 2014.  Zoom in on changes over time. Is it easier to identify the holiday sales bump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot sales over time for 2014\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Refining Using Time Series Statistics\n",
    "\n",
    "**Warning** Prior to version 0.18.0, pd.rolling_*, pd.expanding_*, and pd.ewm* were module level functions and are now deprecated. These are replaced by using the Rolling, Expanding and EWM. objects and a corresponding method call.\n",
    "The deprecation warning will show the new syntax, see an example [here](http://pandas.pydata.org/pandas-docs/stable/whatsnew.html#whatsnew-0180-window-deprecations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure how much the sales are correlated with each other, we want to compute the autocorrelation of the 'Sales' column. In pandas, we do this we with the autocorr function.  \n",
    "`autocorr` takes one argument, the `lag` - which is how many prior data points should be used to compute the correlation. If we set the lag to 1, we compute the correlation between every point and the point directly preceding it, while setting lag to 10, computes the correlation between every point and the point 10 days earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Daily correlation\n",
    "print store1_data['Sales'].resample('D').mean().autocorr(lag=1)\n",
    "\n",
    "# Weekly correlation\n",
    "print store1_data['Sales'].resample('D').mean().autocorr(lag=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to investigate trends over time in sales, as always, we will start by computing simple aggregates.  We want to know what the mean and median sales were for each month and year.\n",
    "\n",
    "In Pandas, this is performed using the `resample` command, which is very similar to the `groupby` command. It allows us to group over different time intervals.\n",
    "\n",
    "We can use `data.resample` and provide as arguments:\n",
    "    - The level on which to roll-up to, 'D' for day, 'W' for week, 'M' for month, 'A' for year\n",
    "    - What aggregation to perform: 'mean', 'median', 'sum', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['2014'][['Sales']].resample('M').mean().add_suffix('_Mean').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['2014'][['Sales']].resample('M').median().add_suffix('_Median').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['2014']['Sales'].resample('D').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While identifying the monthly averages are useful, we often want to compare the sales data of a date to a smaller window. To understand holidays sales, we don't want to compare late December with the entire month, but perhaps a few days surrounding it. We can do this using rolling averages.\n",
    "\n",
    "In pandas, we can compute rolling average using the `pd.rolling_mean` or `pd.rolling_median` functions.\n",
    "\n",
    "`rolling_mean` (as well as `rolling_median`) takes these important parameters:\n",
    "- the first is the series to aggregate\n",
    "- `window` is the number of days to include in the average\n",
    "- `center` is whether the window should be centered on the date or use data prior to that date\n",
    "- `freq` is on what level to roll-up the averages to (as used in `resample`). Either `D` for day, `M` for month or `A` for year, etc.\n",
    "\n",
    "Instead of plotting the full timeseries, we can plot the rolling mean instead, which smooths random changes in sales as well as removing outliers, helping us identify larger trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['2014']['Sales'].rolling(freq='D', window=3, center=True).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['Sales'].rolling(freq='D', window=3, center=True).mean()['2014'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "store1_data['Sales'].rolling(freq='D', window=7, center=True).mean()['2014'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['Sales'].rolling(freq='D', window=30, center=True).mean()['2014'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we discussed earlier, this averages all values in the window evenly.  However we may want to weight closer values more.\n",
    "\n",
    "For example, for a centered weighted average of 10 days, we want to put emphasis on +/- 1 day versus +/- 5 days.\n",
    "\n",
    "One option to do that is the ewma function or the exponential weighted moving average function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_data['Sales'][::-1].ewm(freq='D', span=30).mean()['2014'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diff\n",
    "Pandas `rolling().mean()` and `rolling().median()` are only two examples of Pandas window function capabilities. Window functions are operate on a set of N consecutive rows (a window) and produce an output.\n",
    "\n",
    "In addition to `rolling().mean()` and `rolling().median()`, there are `rolling().sum()`, `rolling().min()`, `rolling().max()`... and many more.\n",
    "\n",
    "Another common one is `diff`, which takes the difference over time. `pd.diff` takes one arugment, `periods`, which is how many prior rows to use for the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Difference in sales, day by day\n",
    "store1_data[['Sales']].resample('D').mean().diff(periods=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Difference in sales, each day to the same day in the previous week\n",
    "store1_data[['Sales']].resample('D').mean().diff(periods=7).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding functions\n",
    "\n",
    "In addition to the set of `rolling()` functions, Pandas also provides a similar collection of `expanding()` functions, which, instead of using a window of N values, use all values up until that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean of all previous values at each point\n",
    "store1_data['Sales'].expanding(min_periods=1,freq='D').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Plot the distribution of sales by month and compare the effect of promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot sales vs promo\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Are sales more correlated with the prior date, a similar date last year, or a similar date last month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get mean daily sales\n",
    "average_daily_sales = ### FILL IN ###\n",
    "\n",
    "print('Correlation with last day: {}'.format(average_daily_sales['Sales'].### FILL IN ###))\n",
    "print('Correlation with last month: {}'.format(average_daily_sales['Sales'].### FILL IN ###))\n",
    "print('Correlation with last year: {}'.format(average_daily_sales['Sales'].### FILL IN ###))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Plot the 15 day rolling mean of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get mean daily customers across all stores\n",
    "average_daily_sales = ### FILL IN ###\n",
    "\n",
    "# Get 15 day rolling mean\n",
    "average_daily_sales### FILL IN ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Identify the date with largest drop in sales from the same date in the previous week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get average daily sales difference with previous week\n",
    "average_daily_sales = ### FILL IN ###\n",
    "average_daily_sales['DiffVsLastWeek'] = ### FILL IN ###\n",
    "\n",
    "# Get top 5 sorted rows\n",
    "print average_daily_sales.sort_values(by='DiffVsLastWeek').head()\n",
    "\n",
    "# Get top 5 sorted rows for open days\n",
    "print average_daily_sales[average_daily_sales.Open == 1].sort_values(by='DiffVsLastWeek').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Compute the total sales up until Dec. 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get total daily sales across all stores\n",
    "total_daily_sales = data[['Sales']].resample('D').sum()\n",
    "\n",
    "# Get total sales up until Dec 2014\n",
    "total_daily_sales.expanding(min_periods=1).sum()['2014-12'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 When were the largest differences between 15-day moving/rolling averages?\n",
    "\n",
    "Hint: Using `rolling_mean` and `diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get mean daily sales across all stores\n",
    "average_daily_sales = ### FILL IN ###\n",
    "\n",
    "# Get largest 15-day rolling average difference\n",
    "average_daily_sales.### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
