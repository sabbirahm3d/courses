{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 16 - Starter Code\n",
    "\n",
    "Exploring Walmart Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Pre-Process\n",
    "\n",
    "Walmart Sales Data\n",
    "\n",
    "For this exercise, we will analyze the weekly sales data from Walmart over a two year period from 2010 to 2012.\n",
    "\n",
    "The data is again separated by store and by department, but we will focus on analyzing one store for simplicity.\n",
    "\n",
    "The data includes:\n",
    "\n",
    "- Store - the store number\n",
    "- Dept - the department number\n",
    "- Date - the week\n",
    "- Weekly_Sales -  sales for the given department in the given store\n",
    "- IsHoliday - whether the week is a special holiday week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../../assets/dataset/train.csv')\n",
    "\n",
    "# Check info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to datetime object\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Use `Date` as index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Check sample\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Filter the dataframe to Store 1 sales and aggregate over departments to compute the total sales per store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter to store 1 sales and average over weeks\n",
    "store1_sales = data[data['Store']==1]\n",
    "\n",
    "# Aggregate weekly total sales\n",
    "store1_sales = store1_sales[['Weekly_Sales']].resample('W').sum()\n",
    "\n",
    "# Check weekly total sales\n",
    "store1_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Plot the rolling_mean for `Weekly_Sales`. What general trends do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_sales[['Weekly_Sales']].rolling(window=3).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.3 Compute the 1, 2, 52 autocorrelations for `Weekly_Sales` and/or create an autocorrelation plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Autocorrelation 1:  ', store1_sales['Weekly_Sales'].autocorr(1)\n",
    "print 'Autocorrelation 2:  ', store1_sales['Weekly_Sales'].autocorr(2)\n",
    "print 'Autocorrelation 52: ', store1_sales['Weekly_Sales'].autocorr(52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create an autocorrelation plot. What does the autocorrelation plot say about the type of model you want to build?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "\n",
    "# Plot autocorrelation plot using Pandas\n",
    "autocorrelation_plot(store1_sales['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Plot autocorrelation plot using Statsmodels\n",
    "p = plot_acf(store1_sales['Weekly_Sales'], lags=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "p = plot_acf(store1_sales['Weekly_Sales'], lags=30)\n",
    "\n",
    "# Components 1 and 2 seem particularly useful for autoregression, perhaps up to 4\n",
    "# In the plot above notice, spike at around 52 - implying a yearly pattern as well\n",
    "# No random spikes, probably not much use for a moving average model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Split the weekly sales data in a training and test set - using 75% of the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(store1_sales.Weekly_Sales)\n",
    "\n",
    "train = store1_sales.Weekly_Sales[:int(.75*n)]\n",
    "test = store1_sales.Weekly_Sales[int(.75*n):]\n",
    "\n",
    "print min(test.index)\n",
    "print max(test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Create an AR(1) model on the training data and compute the mean absolute error of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (1, 0, 0)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=False, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Plot the residuals - where are their significant errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_acf(model.resid, lags=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Compute and AR(2) model and an ARMA(2, 2) model - does this improve your mean absolute error on the held out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 0, 0)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=True, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 0, 2)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=True, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Finally, compute an ARIMA model to improve your prediction error - iterate on the p, q, and parameters comparing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 1, 3)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=False, \n",
    "    typ='levels'\n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
